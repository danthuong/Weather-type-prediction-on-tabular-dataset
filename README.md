DÆ°á»›i Ä‘Ã¢y lÃ  phiÃªn báº£n Ä‘Æ°á»£c viáº¿t láº¡i, chuyÃªn nghiá»‡p hÆ¡n, trÃ¬nh bÃ y rÃµ rÃ ng vÃ  bá»• sung thÃªm cÃ¡c hÆ°á»›ng dáº«n cáº§n thiáº¿t Ä‘á»ƒ cháº¡y dá»± Ã¡n.

---

# ğŸŒ¦ï¸ PhÃ¢n Loáº¡i Thá»i Tiáº¿t: SVM vs. XGBoost

> **Weather Type Classification on Tabular Dataset**

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng, tá»‘i Æ°u hÃ³a vÃ  so sÃ¡nh hiá»‡u suáº¥t cá»§a hai thuáº­t toÃ¡n há»c mÃ¡y phá»• biáº¿n lÃ  **Logisitic Regression**, **Support Vector Machine (SVM)** vÃ  **XGBoost** (Extreme Gradient Boosting) trong bÃ i toÃ¡n phÃ¢n loáº¡i thá»i tiáº¿t dá»±a trÃªn dá»¯ liá»‡u dáº¡ng báº£ng.

---

## ğŸ“‘ Má»¥c Lá»¥c
1. [Giá»›i thiá»‡u dá»± Ã¡n](#-giá»›i-thiá»‡u-dá»±-Ã¡n)
2. [Dá»¯ liá»‡u](#-dá»¯-liá»‡u)
3. [Cáº¥u trÃºc dá»± Ã¡n](#-cáº¥u-trÃºc-dá»±-Ã¡n)
4. [CÃ i Ä‘áº·t vÃ  Sá»­ dá»¥ng](#-cÃ i-Ä‘áº·t-vÃ -sá»­-dá»¥ng)
5. [PhÃ¢n cÃ´ng nhiá»‡m vá»¥](#-phÃ¢n-cÃ´ng-nhiá»‡m-vá»¥)
6. [YÃªu cáº§u bÃ¡o cÃ¡o](#-yÃªu-cáº§u-bÃ¡o-cÃ¡o)
7. [Lá»‹ch trÃ¬nh](#-lá»‹ch-trÃ¬nh)

---

## ğŸš€ Giá»›i thiá»‡u dá»± Ã¡n

Má»¥c tiÃªu chÃ­nh cá»§a dá»± Ã¡n lÃ  giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a lá»›p (Multi-class classification) Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c loáº¡i hÃ¬nh thá»i tiáº¿t. Quy trÃ¬nh thá»±c hiá»‡n bao gá»“m:

1.  **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing):** LÃ m sáº¡ch dá»¯ liá»‡u, xá»­ lÃ½ missing values, mÃ£ hÃ³a (Encoding) vÃ  chuáº©n hÃ³a (Scaling).
2.  **MÃ´ hÃ¬nh hÃ³a (Modeling):**
    *   **Logistic Regression:** MÃ´ hÃ¬nh tuyáº¿n tÃ­nh sá»­ dá»¥ng hÃ m Softmax Ä‘á»ƒ phÃ¢n loáº¡i Ä‘a lá»›p, yÃªu cáº§u chuáº©n hÃ³a dá»¯ liá»‡u vÃ  thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng lÃ m baseline do tÃ­nh Ä‘Æ¡n giáº£n vÃ  kháº£ nÄƒng diá»…n giáº£i tá»‘t.
    *   **SVM:** Táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng siÃªu pháº³ng phÃ¢n tÃ¡ch tá»‘i Æ°u, yÃªu cáº§u ká»¹ lÆ°á»¡ng vá» scaling dá»¯ liá»‡u.
    *   **XGBoost:** Sá»­ dá»¥ng ká»¹ thuáº­t boosting trÃªn cÃ¢y quyáº¿t Ä‘á»‹nh, táº­p trung vÃ o tá»‘c Ä‘á»™ vÃ  hiá»‡u suáº¥t cao.
3.  **Tá»‘i Æ°u tham sá»‘ (Hyperparameter Tuning):** Sá»­ dá»¥ng GridSearch hoáº·c RandomizedSearch Ä‘á»ƒ tÃ¬m bá»™ tham sá»‘ tá»‘t nháº¥t.
4.  **ÄÃ¡nh giÃ¡ & So sÃ¡nh:** PhÃ¢n tÃ­ch káº¿t quáº£ dá»±a trÃªn Accuracy, F1-Score, Precision, Recall vÃ  Confusion Matrix.

---

## ğŸ“Š Dá»¯ liá»‡u

Dá»± Ã¡n sá»­ dá»¥ng bá»™ dá»¯ liá»‡u **Weather Type Classification** tá»« Kaggle.
*   **Nguá»“n dá»¯ liá»‡u:** [Kaggle Dataset Link](https://www.kaggle.com/datasets/nikhil7280/weather-type-classification)
*   **Loáº¡i dá»¯ liá»‡u:** Dáº¡ng báº£ng (Tabular data).
*   **Target:** CÃ¡c loáº¡i hÃ¬nh thá»i tiáº¿t (VÃ­ dá»¥: Sunny, Rainy, Cloudy, Snowy...).

---

## ğŸ“‚ Cáº¥u trÃºc dá»± Ã¡n

```bash
Weather-Type-Prediction/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                    # Chá»©a dá»¯ liá»‡u thÃ´ táº£i vá» tá»« Kaggle (weather_data.csv)
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks cho tá»«ng giai Ä‘oáº¡n
â”‚   â”œâ”€â”€ 1_data_exploration.ipynb    # KhÃ¡m phÃ¡ dá»¯ liá»‡u sÆ¡ bá»™
â”‚   â”œâ”€â”€ 01_EDA_Preprocessing.ipynb  # PhÃ¢n tÃ­ch sÃ¢u vÃ  tiá»n xá»­ lÃ½
â”‚   â””â”€â”€ 02_ModelingSelection.ipynb  # Huáº¥n luyá»‡n, tinh chá»‰nh vÃ  so sÃ¡nh mÃ´ hÃ¬nh
â”œâ”€â”€ src/                        # MÃ£ nguá»“n Python (Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng)
â”‚   â”œâ”€â”€ preprocess.py           # CÃ¡c hÃ m xá»­ lÃ½, lÃ m sáº¡ch dá»¯ liá»‡u
â”‚   â””â”€â”€ utils.py                # CÃ¡c hÃ m há»— trá»£ (Ä‘Ã¡nh giÃ¡, váº½ biá»ƒu Ä‘á»“...)
â”œâ”€â”€ requirements.txt            # Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
â””â”€â”€ README.md                   # TÃ i liá»‡u dá»± Ã¡n
```

---

## ğŸ›  CÃ i Ä‘áº·t vÃ  Sá»­ dá»¥ng

1.  **Clone dá»± Ã¡n:**
    ```bash
    git clone https://github.com/danthuong/Weather-type-prediction-on-tabular-dataset.git
    cd Weather-type-prediction-on-tabular-dataset
    ```

2.  **CÃ i Ä‘áº·t mÃ´i trÆ°á»ng:**
    KhuyÃªn dÃ¹ng mÃ´i trÆ°á»ng áº£o (Virtual Environment):
    ```bash
    python -m venv venv
    source venv/bin/activate  # TrÃªn Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  **Cháº¡y Notebook:**
    Má»Ÿ cÃ¡c file trong thÆ° má»¥c `notebooks/` theo thá»© tá»± Ä‘Ã£ Ä‘Ã¡nh sá»‘ Ä‘á»ƒ theo dÃµi quy trÃ¬nh.

---

## ğŸ‘¥ PhÃ¢n cÃ´ng nhiá»‡m vá»¥

| Task | ThÃ nh viÃªn | MÃ´ táº£ cÃ´ng viá»‡c chi tiáº¿t |
| :--- | :--- | :--- |
| **Task 1: SVM Model** | `[DÅ©ng, Chiáº¿n]` | - PhÃ¢n tÃ­ch Ä‘áº·c thÃ¹ dá»¯ liá»‡u cho SVM + LogisticRegression.<br>- Huáº¥n luyá»‡n vÃ  Tuning SVM.<br>- Viáº¿t bÃ¡o cÃ¡o chuyÃªn sÃ¢u vá» SVM. |
| **Task 2: XGBoost Model** | `[DÆ°Æ¡ng, Nhi]` | - PhÃ¢n tÃ­ch Ä‘áº·c thÃ¹ dá»¯ liá»‡u cho XGBoost.<br>- Huáº¥n luyá»‡n vÃ  Tuning XGBoost.<br>- Viáº¿t bÃ¡o cÃ¡o chuyÃªn sÃ¢u vá» XGBoost. |
| **Task 3: ÄÃ¡nh giÃ¡ chung** | `ToÃ n team` | - Thá»‘ng nháº¥t metrics Ä‘Ã¡nh giÃ¡.<br>- Viáº¿t script so sÃ¡nh.<br>- Tá»•ng há»£p káº¿t quáº£ vÃ  viáº¿t káº¿t luáº­n chung. |

---

## ğŸ“ YÃªu cáº§u bÃ¡o cÃ¡o

BÃ¡o cÃ¡o cáº§n Ä‘Æ°á»£c trÃ¬nh bÃ y **chi tiáº¿t, mang tÃ­nh há»c thuáº­t vÃ  giáº£i thÃ­ch rÃµ rÃ ng** Ä‘á»ƒ ngÆ°á»i Ä‘á»c (ká»ƒ cáº£ ngÆ°á»i má»›i) cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c. Cáº¥u trÃºc báº¯t buá»™c:

### 1. Giá»›i thiá»‡u thuáº­t toÃ¡n
*   **KhÃ¡i niá»‡m cá»‘t lÃµi:** Äá»‹nh nghÄ©a SVM/XGBoost lÃ  gÃ¬?
*   **CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:**
    *   *Logistic Regression:* Linear decision boundary, Sigmoid/Softmax, Cross-Entropy loss, L2 regularization.
    *   *SVM:* Support vectors, Margin, Kernel Trick ($C$, $\gamma$...).
    *   *XGBoost:* Gradient Boosting, Decision Trees, Regularization, Loss function.
*   **Æ¯u/NhÆ°á»£c Ä‘iá»ƒm lÃ½ thuyáº¿t:** Khi nÃ o nÃªn dÃ¹ng?

### 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing)
*   **LÃ½ do thá»±c hiá»‡n:** Táº¡i sao thuáº­t toÃ¡n nÃ y láº¡i cáº§n bÆ°á»›c xá»­ lÃ½ Ä‘Ã³?
    *   *VÃ­ dá»¥ SVM:* Táº¡i sao pháº£i dÃ¹ng StandardScaler/MinMaxScaler?
    *   *VÃ­ dá»¥ XGBoost:* Xá»­ lÃ½ biáº¿n category (One-Hot vs Label Encoding) áº£nh hÆ°á»Ÿng tháº¿ nÃ o?
*   **Quy trÃ¬nh:** Liá»‡t kÃª cÃ¡c bÆ°á»›c lÃ m sáº¡ch vÃ  biáº¿n Ä‘á»•i dá»¯ liá»‡u Ä‘Ã£ Ã¡p dá»¥ng.

### 3. XÃ¢y dá»±ng mÃ´ hÃ¬nh (Modeling)
*   **QuÃ¡ trÃ¬nh huáº¥n luyá»‡n:** CÃ¡c bÆ°á»›c train model.
*   **Hyperparameters:** Giáº£i thÃ­ch Ã½ nghÄ©a cÃ¡c tham sá»‘ quan trá»ng Ä‘Ã£ tinh chá»‰nh.
*   **PhÆ°Æ¡ng phÃ¡p Tuning:** GridSearch hay RandomizedSearch? Táº¡i sao chá»n khÃ´ng gian tham sá»‘ Ä‘Ã³?

### 4. Káº¿t quáº£ & PhÃ¢n tÃ­ch (Evaluation)
*   **Káº¿t quáº£ Ä‘á»‹nh lÆ°á»£ng:** Báº£ng sá»‘ liá»‡u (Accuracy, F1-Score...).
*   **Káº¿t quáº£ Ä‘á»‹nh tÃ­nh:** Confusion Matrix, ROC Curve.
*   **PhÃ¢n tÃ­ch sÃ¢u:** Model nháº­n diá»‡n tá»‘t lá»›p nÃ o? KÃ©m lá»›p nÃ o? Táº¡i sao (do dá»¯ liá»‡u máº¥t cÃ¢n báº±ng hay do Ä‘áº·c trÆ°ng)?

### 5. Káº¿t luáº­n
*   Tá»•ng káº¿t láº¡i hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n Ä‘á»‘i vá»›i bá»™ dá»¯ liá»‡u nÃ y.

---

## ğŸ“… Deadline
*   **Deadline hoÃ n thÃ nh:** `23/11/2025`